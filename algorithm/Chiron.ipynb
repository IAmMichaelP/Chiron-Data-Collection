{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to your model directory\n",
    "model_path = \"./distilbert_model4\"\n",
    "general_model_path = \"./general_model\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "general_tokenizer = DistilBertTokenizer.from_pretrained(general_model_path)\n",
    "\n",
    "# Load the model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "general_model = DistilBertForSequenceClassification.from_pretrained(general_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Example: Classify a news article\n",
    "def classify_news(text, tokenizer, model, max_length=512):\n",
    "    \"\"\"\n",
    "    Classify news content as \"authentic\" or \"fake\".\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The news content to classify.\n",
    "        tokenizer: The DistilBERT tokenizer.\n",
    "        model: The fine-tuned DistilBERT model.\n",
    "        max_length (int): Maximum length of the input sequence.\n",
    "\n",
    "    Returns:\n",
    "        str: \"authentic\" or \"fake\".\n",
    "    \"\"\" \n",
    "    # Preprocess the input text\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"  # Return PyTorch tensors\n",
    "    )\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "        \n",
    "    print(\"-----\")\n",
    "    print(\"This is the value: \")\n",
    "    print(predicted_class)\n",
    "    \n",
    "\n",
    "    # Map predicted class index to label\n",
    "    labels = [\"fake\", \"authentic\"]  # Ensure this matches your training labels\n",
    "    return labels[predicted_class]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Classify a news article\n",
    "def classify_health_news(text, tokenizer, model, max_length=512):\n",
    "    \"\"\"\n",
    "    Classify news content as \"authentic\" or \"fake\".\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The news content to classify.\n",
    "        tokenizer: The DistilBERT tokenizer.\n",
    "        model: The fine-tuned DistilBERT model.\n",
    "        max_length (int): Maximum length of the input sequence.\n",
    "\n",
    "    Returns:\n",
    "        str: \"authentic\" or \"fake\".\n",
    "    \"\"\" \n",
    "    # Preprocess the input text\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"  # Return PyTorch tensors\n",
    "    )\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "        \n",
    "    print(\"-----\")\n",
    "    print(\"This is the value: \")\n",
    "    print(predicted_class)\n",
    "\n",
    "    if predicted_class == 1:\n",
    "        classification_result = classify_news(text, tokenizer, model)\n",
    "        print(f\"The news is classified as: {classification_result}\")\n",
    "\n",
    "\n",
    "    # Map predicted class index to label\n",
    "    labels = [\"general\", \"health\"]  # Ensure this matches your training labels\n",
    "    return labels[predicted_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "This is the value: \n",
      "0\n",
      "The news is classified as: general\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    news_content = \"\"\"\n",
    "SM Supermalls and the Estée Lauder Companies (ELC) stand united in their mission to educate, empower, and support those affected by breast cancer, kicking off the numerous activities in store for Breast Cancer Awareness Month on October 3, 2024, at SM Aura’s Upper Ground Atrium.Following the theme “Beautifully United to Help End Breast Cancer,” Estée Lauder partnered with SM Supermalls to launch an impactful month dedicated to raising awareness and providing essential resources in the fight against breast cancer.The press event was meant to bring together, educate, and inspire advocates, medical experts, and community members.“At SM Supermalls, we recognize our responsibility to support and empower women and women’s health. As a society, we must work together to enhance breast cancer awareness and response. By promoting a supportive community, advocating for better access to healthcare, and empowering individuals with knowledge, we can make a significant impact,” said SM Supermalls President Steven Tan.The press event featured insightful talks from esteemed speakers, including Dr. Helen Amo, a surgical oncologist, who shared crucial information about the disease. Celebrity fashion stylist and inspirational speaker Kat Cruz moved attendees with her personal story of embracing courage in the face of breast cancer, illustrating the hope and resilience of those affected. Editor Chit Lijauco also shared her experience as a breast cancer patient and victor.Additionally, free breast health exams were offered to the mall-goers of SM Aura as part of the push for early detection and regular screening.Landmarks such as the SM Mall of Asia Globe and facade, SM Aura façade, SM Megamall’s Time Sculpture, façade, and Mega Tower, SM Lanang in Davao façade and fountain, and SM Seaside City Cebu’s façade and The Cube, were also illuminated in pink, sending a powerful message of solidarity.Through these collaborative efforts, SM Supermalls is not just raising awareness for breast cancer—it is also providing vital resources that can lead to early detection and improved health outcomes. For more information on SM Supermalls and to stay updated, visit www.smsupermalls.com or follow SM Supermalls on Facebook.\n",
    "\n",
    "\"\"\"\n",
    "    # # Classify the news\n",
    "    # result = classify_news(news_content, tokenizer, model)\n",
    "    # print(f\"The news is classified as: {result}\")\n",
    "\n",
    "    result = classify_health_news(news_content, general_tokenizer, general_model)\n",
    "    print(f\"The news is classified as: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Make sure `classify_news`, `tokenizer`, and `model` are defined/imported earlier\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Load your CSV\n",
    "#     df = pd.read_csv(r\"annotated_dataset4.csv\")\n",
    "\n",
    "#     for index, row in df.iterrows():\n",
    "#         news_content = row['content']\n",
    "#         expected_annotation = row.get('annotation', 'N/A')  # use .get in case the column is missing\n",
    "\n",
    "#         try:\n",
    "#             result = classify_news(news_content, tokenizer, model)\n",
    "            \n",
    "#             print(f\"Row {index}\")\n",
    "#             print(f\"News Content:\\n{news_content[:200]}...\")  # show only first 200 characters\n",
    "#             print(f\"Predicted: {result}\")\n",
    "#             print(f\"Annotation: {expected_annotation}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing row {index}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
